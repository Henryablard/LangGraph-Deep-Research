#å¤šå±‚çº§çˆ¶å­é—®é¢˜èœå•
from typing import List, Dict, Optional
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_community.tools.tavily_search import TavilySearchResults

# åˆå§‹åŒ–

load_dotenv()

embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = Chroma(
    collection_name="interactive_research_memory",
    embedding_function=embeddings,
    persist_directory="./chroma_db"
)
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
tavily = TavilySearchResults(max_results=5)

# æ•°æ®ç»“æ„

class QuestionNode:
    def __init__(self, text: str, parent=None):
        self.text: str = text
        self.parent: Optional['QuestionNode'] = parent
        self.children: List['QuestionNode'] = []
        self.summary: Optional[str] = None
        self.is_researched: bool = False

# å·¥å…·å‡½æ•°

def planner(topic: str) -> List[str]:
    prompt = (
        f"ä¸»é¢˜: {topic}\n\n"
        "è¯·å°†è¿™ä¸ªä¸»é¢˜æ‹†è§£ä¸º3-5ä¸ªå…³é”®å­é—®é¢˜ï¼Œè¦†ç›–ç°çŠ¶ã€åº”ç”¨ã€æŠ€æœ¯ã€æŒ‘æˆ˜ã€è¶‹åŠ¿ã€‚\n"
        "è¾“å‡ºJSONæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­é—®é¢˜ã€‚"
    )
    resp = llm.invoke(prompt)
    try:
        sub_qs = json.loads(resp.content)
    except:
        sub_qs = [topic]
    return sub_qs

def search_and_display(query: str) -> List[Dict]:
    docs: List[Dict] = tavily.invoke(query)
    if not docs:
        return []
    return [d for d in docs if isinstance(d, dict)]

def summarize(query: str, docs: List[Dict]) -> str:
    joined = "\n\n".join(
        f"[{i+1}] {item.get('title','æ— æ ‡é¢˜')}\nURL: {item.get('url','æ— URL')}\n{item.get('content','')}"
        for i, item in enumerate(docs)
    )
    prompt = (
        f"å­é—®é¢˜: {query}\n\n"
        "ä»¥ä¸‹æ˜¯ç›¸å…³èµ„æ–™ï¼Œè¯·æ€»ç»“ä¸ºè¦ç‚¹ï¼ˆ<=6æ¡ï¼‰ï¼Œå¹¶ä¿æŒå¼•ç”¨ [1][2]ï¼š\n\n"
        f"{joined}\n\nè¦ç‚¹ï¼š"
    )
    resp = llm.invoke(prompt)
    return getattr(resp, "content", str(resp))

def save_to_memory(query: str, summary: str):
    doc_id = str(uuid.uuid4())
    today = date.today().isoformat()
    content = f"ã€æŸ¥è¯¢ã€‘{query} ({today})\n\n{summary}"
    vectorstore.add_texts([content], metadatas=[{"query": query, "date": today}], ids=[doc_id])

def retrieve_memory(query: str):
    docs = vectorstore.similarity_search(query, k=2)
    return docs

# æ„å»ºçˆ¶å­æ ‘

def build_tree(root_text: str, sub_questions: List[str]) -> QuestionNode:
    root_node = QuestionNode(root_text)
    for sq in sub_questions:
        root_node.children.append(QuestionNode(sq, parent=root_node))
    return root_node

def add_children_from_summary(node: QuestionNode):
    if node.children or not node.summary:
        return
    lines = [line.strip() for line in node.summary.split("\n") if line.strip()]
    for line in lines:
        if line[0].isdigit():
            node.children.append(QuestionNode(line, parent=node))

# ç ”ç©¶èŠ‚ç‚¹

def research_node(node: QuestionNode):
    if node.is_researched:
        return
    retrieve_memory(node.text)
    docs = search_and_display(node.text)
    if docs:
        node.summary = summarize(node.text, docs)
        save_to_memory(node.text, node.summary)
    else:
        node.summary = "æœªæ‰¾åˆ°èµ„æ–™"
    node.is_researched = True
    add_children_from_summary(node)

# èœå•æ˜¾ç¤ºé€»è¾‘

def show_menu(node: QuestionNode, is_root=False) -> Dict:
    """è¿”å›èœå•æ–‡æœ¬å’Œç¼–å·æ˜ å°„"""
    menu_text = f"\nğŸ“ å½“å‰èœå•: {node.text}\n"
    option_mapping = {}
    for i, child in enumerate(node.children, 1):
        summary_preview = child.summary.split("\n")[0] if child.summary else "âŒ æœªç ”ç©¶"
        menu_text += f"{i}. {child.text} | ğŸ” {summary_preview}\n"
        option_mapping[i] = ("child", child)
    idx_offset = len(node.children)

    # æ ¹èŠ‚ç‚¹é¢å¤–æ“ä½œ
    extra_options = []
    if is_root:
        extra_options = [
            ("æ·»åŠ è‡ªå®šä¹‰é—®é¢˜", "custom"),
            ("æŸ¥çœ‹å·²ç ”ç©¶æ€»ç»“", "view_summaries"),
            ("ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š", "generate_report"),
            ("é€€å‡º", "exit")
        ]
    else:
        extra_options = [("è¿”å›ä¸Šä¸€çº§", "back")]

    for j, (label, action) in enumerate(extra_options, idx_offset + 1):
        menu_text += f"{j}. {label}\n"
        option_mapping[j] = (action, None)

    return menu_text, option_mapping


# æ”¶é›†æ‰€æœ‰æ€»ç»“

def collect_summaries(node: QuestionNode) -> Dict[str, str]:
    summaries = {}
    def _collect(n: QuestionNode):
        if n.summary:
            summaries[n.text] = n.summary
        for c in n.children:
            _collect(c)
    _collect(node)
    return summaries

# ä¸»å¾ªç¯

if __name__ == "__main__":
    print("å¤šè½®äº¤äº’ç ”ç©¶ Agent")
    topic = input("è¯·è¾“å…¥ç ”ç©¶ä¸»é¢˜: ").strip()
    sub_questions = planner(topic)
    root_node = build_tree(topic, sub_questions)
    stack: List[QuestionNode] = [root_node]

    while stack:
        current_node = stack[-1]
        is_root = (current_node.parent is None)
        menu_text, option_mapping = show_menu(current_node, is_root=is_root)
        choice = input(menu_text + "è¯·è¾“å…¥ç¼–å·: ").strip()

        if not choice.isdigit():
            print("âš ï¸ è¯·è¾“å…¥æ•°å­—ç¼–å·ã€‚")
            continue
        choice = int(choice)
        if choice not in option_mapping:
            print("âš ï¸ æ— æ•ˆé€‰æ‹©ã€‚")
            continue

        action, param = option_mapping[choice]

        if action == "child":
            node = param
            research_node(node)
            if node.children:
                stack.append(node)
            else:
                print(f"\nğŸ“Œ {node.text} çš„æ€»ç»“ï¼š\n{node.summary}\n")
        elif action == "back":
            stack.pop()
        elif action == "custom":
            q = input("è¯·è¾“å…¥è‡ªå®šä¹‰é—®é¢˜: ").strip()
            new_node = QuestionNode(q, parent=current_node)
            current_node.children.append(new_node)
            research_node(new_node)
        elif action == "view_summaries":
            summaries = collect_summaries(root_node)
            print("\nğŸ“‚ å·²ç ”ç©¶æ€»ç»“ï¼š")
            for k, v in summaries.items():
                print(f"\n--- {k} ---\n{v}\n")
        elif action == "generate_report":
            summaries = collect_summaries(root_node)
            report = final_report(topic, summaries)
            print("\nğŸ“˜ æœ€ç»ˆç ”ç©¶æŠ¥å‘Šï¼š\n")
            print(report)
            with open("interactive_research_report.txt","w",encoding="utf-8") as f:
                f.write(report)
            print("âœ… å·²ä¿å­˜ä¸º interactive_research_report.txt")
        elif action == "exit":
            print("ğŸ‘‹ å·²é€€å‡ºã€‚")
            break

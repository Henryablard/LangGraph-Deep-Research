#äº¤äº’research
from typing import List, Dict
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_community.tools.tavily_search import TavilySearchResults
import uuid
from datetime import date

# åˆå§‹åŒ–
load_dotenv()
embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
vectorstore = Chroma(
    collection_name="interactive_search_memory",
    embedding_function=embeddings,
    persist_directory="./chroma_db"
)

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)
tavily = TavilySearchResults(max_results=5)

def search_and_display(query: str) -> List[Dict]:
    """è°ƒç”¨ Tavily æœç´¢å¹¶æ‰“å°ç»“æœ"""
    docs: List[Dict] = tavily.invoke(query)
    if not docs:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç»“æœã€‚")
        return []
    for i, d in enumerate(docs, 1):
        print(f"\n[{i}] {d.get('title')}")
        print(f"URL: {d.get('url')}")
        print(f"{d.get('content')[:200]}...")  # åªæ˜¾ç¤ºå‰200å­—
    return docs

def summarize(query: str, docs: List[Dict]) -> str:
    """è°ƒç”¨ LLM æ€»ç»“"""
    joined = "\n\n".join(
        f"[{i+1}] {item.get('title')}\nURL: {item.get('url')}\n{item.get('content')}"
        for i, item in enumerate(docs)
    )
    prompt = (
        f"ç”¨æˆ·æŸ¥è¯¢: {query}\n\n"
        "ä»¥ä¸‹æ˜¯ç›¸å…³èµ„æ–™ï¼Œè¯·æ€»ç»“ä¸ºè¦ç‚¹ï¼ˆ<=6æ¡ï¼‰ï¼Œå¹¶ä¿æŒå¼•ç”¨ [1][2]ï¼š\n\n"
        f"{joined}\n\nè¦ç‚¹ï¼š"
    )
    resp = llm.invoke(prompt)
    print("\nğŸ“Œ æ€»ç»“ç»“æœï¼š\n")
    print(resp.content)
    return resp.content

def save_to_memory(query: str, summary: str):
    """å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“"""
    doc_id = str(uuid.uuid4())
    today = date.today().isoformat()
    content = f"ã€æŸ¥è¯¢ã€‘{query} ({today})\n\n{summary}"
    vectorstore.add_texts([content], metadatas=[{"query": query, "date": today}], ids=[doc_id])
    print("âœ… å·²ä¿å­˜åˆ°æœ¬åœ°è®°å¿†åº“ã€‚")

def retrieve_memory(query: str):
    """ä»å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢"""
    docs = vectorstore.similarity_search(query, k=2)
    if not docs:
        print("ğŸ“‚ è®°å¿†åº“ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹ã€‚")
    else:
        print("\nğŸ“‚ è®°å¿†åº“æ£€ç´¢ç»“æœï¼š")
        for d in docs:
            print(d.page_content[:200], "...\n")

# ä¸»äº¤äº’å¾ªç¯
if __name__ == "__main__":
    print("=== äº¤äº’å¼æœç´¢ Agent ===")
    print("è¾“å…¥ä¸»é¢˜è¿›è¡Œæœç´¢ï¼Œè¾“å…¥ `exit` é€€å‡ºã€‚")

    while True:
        query = input("\nè¯·è¾“å…¥æœç´¢ä¸»é¢˜: ").strip()
        if query.lower() == "exit":
            break

        # æ£€ç´¢è®°å¿†
        retrieve_memory(query)

        # æœç´¢å¹¶å±•ç¤º
        docs = search_and_display(query)
        if not docs:
            continue

        # æ˜¯å¦æ€»ç»“
        do_sum = input("\næ˜¯å¦ç”Ÿæˆæ€»ç»“ï¼Ÿ(y/n): ").strip().lower()
        if do_sum == "y":
            summary = summarize(query, docs)

            # ä¿å­˜
            do_save = input("\næ˜¯å¦ä¿å­˜åˆ°è®°å¿†åº“ï¼Ÿ(y/n): ").strip().lower()
            if do_save == "y":
                save_to_memory(query, summary)

    print("ğŸ‘‹ å·²é€€å‡ºã€‚")

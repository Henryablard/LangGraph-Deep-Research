import os
import re
import requests
from langchain_tavily import TavilySearch
from langgraph.prebuilt import create_react_agent
from langchain.tools import tool
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model

# 1. Tavily å·¥å…·ï¼ˆç½‘é¡µæœç´¢ï¼‰
load_dotenv()

tavily_tool = TavilySearch(
    api_key=os.getenv("TAVILY_API_KEY"),
    max_results=5
)

# 2. OpenWeatherMap å·¥å…·ï¼ˆæŸ¥å¤©æ°”ï¼‰
@tool
def get_weather(city: str):
    """æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å®æ—¶å¤©æ°”ï¼ˆé€šè¿‡ OpenWeatherMap APIï¼‰ã€‚"""
    api_key = os.getenv("OPENWEATHER_API_KEY")
    if not api_key:
        return "âŒ æ²¡æœ‰æ‰¾åˆ° OPENWEATHER_API_KEYï¼Œè¯·å…ˆåœ¨ç¯å¢ƒå˜é‡é‡Œé…ç½®ã€‚"

    url = f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}&lang=zh_cn&units=metric"
    resp = requests.get(url)
    if resp.status_code != 200:
        return f"âŒ æŸ¥è¯¢å¤©æ°”å¤±è´¥: {resp.text}"
    data = resp.json()
    return {
        "åŸå¸‚": city,
        "å¤©æ°”": data["weather"][0]["description"],
        "æ¸©åº¦": f"{data['main']['temp']}Â°C",
        "ä½“æ„Ÿæ¸©åº¦": f"{data['main']['feels_like']}Â°C",
        "æ¹¿åº¦": f"{data['main']['humidity']}%"
    }

# 3. æ³¨å†Œå·¥å…·
tools = [tavily_tool, get_weather]

# 4. åˆ›å»ºæ™ºèƒ½ä½“
agent = create_react_agent(
    model="openai:gpt-4o-mini",
    tools=tools,
    prompt=(
        "ä½ æ˜¯ä¸€ä¸ªæ—…è¡Œè§„åˆ’åŠ©æ‰‹ã€‚"
        "å½“ç”¨æˆ·éœ€è¦å®æ—¶å¤©æ°”æ—¶ï¼Œå¿…é¡»è°ƒç”¨ get_weather å·¥å…·ï¼›"
        "å½“ç”¨æˆ·éœ€è¦æ—…æ¸¸ä¿¡æ¯æ—¶ï¼Œè¯·è°ƒç”¨ Tavilyã€‚"
    )
)

# 5. åˆå§‹åŒ–ä¸€ä¸ªå°æ¨¡å‹æ¥æå–åŸå¸‚ï¼ˆå…œåº•ç”¨ï¼‰
llm_extractor = init_chat_model("openai:gpt-4o-mini")

def extract_city(user_input: str) -> str:
    """ä¼˜å…ˆç”¨æ­£åˆ™åŒ¹é…åŸå¸‚ï¼ŒåŒ¹é…ä¸åˆ°å°±ç”¨ LLM æå–"""
    # ç®€å•çš„ä¸­æ–‡åŸå¸‚åŒ¹é…
    match = re.search(r"(åŒ—äº¬|ä¸Šæµ·|å¹¿å·|æ·±åœ³|ä¸œäº¬|å¤§é˜ª|äº¬éƒ½|æ¨ªæ»¨|çº½çº¦|å·´é»|ä¼¦æ•¦)", user_input)
    if match:
        return match.group(1)

    # å¦‚æœæ­£åˆ™æ²¡æ‰¾åˆ° â†’ LLM æå–
    msg = [{"role": "user", "content": f"è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–ä¸€ä¸ªåŸå¸‚åç§°: {user_input}"}]
    response = llm_extractor.invoke(msg)
    return response.content.strip()

# 6. åŒ…è£…ä¸€å±‚ï¼Œå¼ºåˆ¶å¤©æ°”è°ƒç”¨é€»è¾‘
def smart_agent(user_input: str):
    if "å¤©æ°”" in user_input:
        city = extract_city(user_input)
        weather = get_weather(city)
        print("ğŸŒ¤ï¸ å®æ—¶å¤©æ°”:", weather)

        result = agent.invoke(
            {"messages": [
                {"role": "user", "content": f"{user_input} (åŸå¸‚: {city})"}
            ]}
        )
        print("ğŸ¤– Assistant:", result["messages"][-1].content)
    else:
        result = agent.invoke(
            {"messages": [{"role": "user", "content": user_input}]}
        )
        print("ğŸ¤– Assistant:", result["messages"][-1].content)

# 7. æµ‹è¯•
if __name__ == "__main__":
    query = "Today is 2025/8/25. Please help me plan a three-day trip to Tokyo this weekend and next Monday, and also check the weather in Tokyo on those days. Please display the planned dates and weather dates as well. Output should be in Chinese."
    smart_agent(query)
